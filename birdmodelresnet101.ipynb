{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/blackfox20092006/birdmodelresnet101?scriptVersionId=237328209\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","execution_count":1,"id":"2d286948","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2025-05-02T04:43:13.296278Z","iopub.status.busy":"2025-05-02T04:43:13.296079Z","iopub.status.idle":"2025-05-02T06:57:48.921665Z","shell.execute_reply":"2025-05-02T06:57:48.920824Z"},"papermill":{"duration":8075.63241,"end_time":"2025-05-02T06:57:48.925793","exception":false,"start_time":"2025-05-02T04:43:13.293383","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth\n","100%|██████████| 171M/171M [00:00<00:00, 229MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/25\n","Train Loss: 4.250948, Accuracy: 0.150202\n","Test Loss: 3.186890, Test Accuracy: 0.317186\n","Saved best model! Accuracy: 0.317186\n","Epoch 2/25\n","Train Loss: 2.537037, Accuracy: 0.427342\n","Test Loss: 2.640505, Test Accuracy: 0.381634\n","Saved best model! Accuracy: 0.381634\n","Epoch 3/25\n","Train Loss: 1.930263, Accuracy: 0.541640\n","Test Loss: 2.413970, Test Accuracy: 0.427970\n","Saved best model! Accuracy: 0.427970\n","Epoch 4/25\n","Train Loss: 1.617702, Accuracy: 0.614617\n","Test Loss: 2.252742, Test Accuracy: 0.443976\n","Saved best model! Accuracy: 0.443976\n","Epoch 5/25\n","Train Loss: 1.399290, Accuracy: 0.660931\n","Test Loss: 2.204371, Test Accuracy: 0.462932\n","Saved best model! Accuracy: 0.462932\n","Epoch 6/25\n","Train Loss: 1.244631, Accuracy: 0.691311\n","Test Loss: 2.163049, Test Accuracy: 0.465038\n","Saved best model! Accuracy: 0.465038\n","Epoch 7/25\n","Train Loss: 1.114475, Accuracy: 0.724347\n","Test Loss: 2.162924, Test Accuracy: 0.471778\n","Saved best model! Accuracy: 0.471778\n","Epoch 8/25\n","Train Loss: 0.995023, Accuracy: 0.755895\n","Test Loss: 2.150045, Test Accuracy: 0.464195\n","Epoch 9/25\n","Train Loss: 0.905905, Accuracy: 0.778309\n","Test Loss: 2.193138, Test Accuracy: 0.459141\n","Epoch 10/25\n","Train Loss: 0.813623, Accuracy: 0.807414\n","Test Loss: 2.109967, Test Accuracy: 0.479781\n","Saved best model! Accuracy: 0.479781\n","Epoch 11/25\n","Train Loss: 0.745385, Accuracy: 0.822605\n","Test Loss: 2.159867, Test Accuracy: 0.467565\n","Epoch 12/25\n","Train Loss: 0.682575, Accuracy: 0.844381\n","Test Loss: 2.142875, Test Accuracy: 0.473884\n","Epoch 13/25\n","Train Loss: 0.636415, Accuracy: 0.852348\n","Test Loss: 2.249865, Test Accuracy: 0.470093\n","Epoch 14/25\n","Train Loss: 0.597045, Accuracy: 0.863714\n","Test Loss: 2.197287, Test Accuracy: 0.470093\n","Epoch 15/25\n","Train Loss: 0.563798, Accuracy: 0.874336\n","Test Loss: 2.241724, Test Accuracy: 0.478939\n","Epoch 16/25\n","Train Loss: 0.525937, Accuracy: 0.887508\n","Test Loss: 2.281507, Test Accuracy: 0.474726\n","Epoch 17/25\n","Train Loss: 0.496294, Accuracy: 0.891757\n","Test Loss: 2.331050, Test Accuracy: 0.473884\n","Epoch 18/25\n","Train Loss: 0.462146, Accuracy: 0.900255\n","Test Loss: 2.314493, Test Accuracy: 0.459983\n","Epoch 19/25\n","Train Loss: 0.439366, Accuracy: 0.907160\n","Test Loss: 2.316789, Test Accuracy: 0.475147\n","Epoch 20/25\n","Train Loss: 0.408578, Accuracy: 0.913427\n","Test Loss: 2.280027, Test Accuracy: 0.474726\n","Epoch 21/25\n","Train Loss: 0.377507, Accuracy: 0.922350\n","Test Loss: 2.281246, Test Accuracy: 0.476832\n","Epoch 22/25\n","Train Loss: 0.366231, Accuracy: 0.929785\n","Test Loss: 2.312678, Test Accuracy: 0.485257\n","Saved best model! Accuracy: 0.485257\n","Epoch 23/25\n","Train Loss: 0.352821, Accuracy: 0.933822\n","Test Loss: 2.327971, Test Accuracy: 0.473884\n","Epoch 24/25\n","Train Loss: 0.340584, Accuracy: 0.935309\n","Test Loss: 2.377454, Test Accuracy: 0.478096\n","Epoch 25/25\n","Train Loss: 0.317286, Accuracy: 0.942851\n","Test Loss: 2.423695, Test Accuracy: 0.465880\n","Best accuracy achieved = 0.485256950294861\n"]}],"source":["import torch\n","from torch import nn\n","from torch.utils.data import DataLoader, Dataset\n","from torchvision import transforms, models\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import cv2\n","import os\n","import random\n","import logging\n","\n","logging.basicConfig(level=logging.INFO)\n","logger = logging.getLogger()\n","\n","# Paths\n","root = '/kaggle/input/bird-species-classification-220-categories'\n","train_path = root + '/Train'\n","test_path = root + '/Test'\n","\n","# Get labels\n","train_labels = [i for i in os.listdir(train_path)]\n","test_labels = [i for i in os.listdir(test_path)]\n","\n","tmp_train_img_paths = [train_path + '/' + j for j in train_labels]\n","tmp_test_img_paths = [test_path + '/' + j for j in test_labels]\n","train_img_paths, test_img_paths = [], []\n","\n","for i in tmp_train_img_paths:\n","    for j in os.listdir(i):\n","        train_img_paths.append(i + '/' + j)\n","for i in tmp_test_img_paths:\n","    for j in os.listdir(i):\n","        test_img_paths.append(i + '/' + j)\n","del tmp_test_img_paths, tmp_train_img_paths\n","\n","random.shuffle(train_img_paths)\n","random.shuffle(test_img_paths)\n","\n","# label2name, name2label\n","label2name, name2label = {}, {}\n","for i in range(len(train_labels)):\n","    label2name[i] = train_labels[i]\n","    name2label[train_labels[i]] = i\n","\n","# ground truth\n","train_labels, test_labels = [], []\n","for i in train_img_paths:\n","    train_labels.append(name2label[i.split('/')[-2]])\n","for j in test_img_paths:\n","    test_labels.append(name2label[j.split('/')[-2]])\n","\n","# Transforms\n","transform = transforms.Compose([\n","    transforms.ToPILImage(),\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                         std=[0.229, 0.224, 0.225])\n","])\n","\n","# Dataset\n","class BirdDataset(Dataset):\n","    def __init__(self, data, labels, transform=None):\n","        self.data = data\n","        self.labels = labels\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, item_index):\n","        img_path = self.data[item_index]\n","        img_ground_truth = self.labels[item_index]\n","        img_data = cv2.imread(img_path)\n","        #img\n","        img_data = cv2.imread(img_path)\n","        if self.transform:\n","            H, W, C = img_data.shape\n","            # print(H, W, C)\n","            T, B, L, R = 0, 0, 0, 0 # top bottom left right\n","            if H > W: # cao hơn rộng => padding chiều rộng\n","                R = H-W\n","            elif H < W: #rộng hơn cao => padding chiều cao\n","                T = W-H\n","            else: #bang nhau\n","                pass\n","            # print(R, T)\n","            transform = transforms.Compose(\n","                [\n","                    transforms.ToPILImage(),\n","                    transforms.Pad(padding=(L, T, R, B), fill=0, padding_mode='constant'), #trái - trên - phải - dưới\n","                    # transforms.RandomRotation(degrees=5),\n","                    # transforms.RandomHorizontalFlip(p=0.5),\n","                    # transforms.ColorJitter(\n","                    #     brightness=0.05,\n","                    #     contrast=0.05,\n","                    #     saturation=0.05,\n","                    #     hue=0.02\n","                    # ),\n","\n","                    transforms.Resize((224, 224)),\n","                    transforms.ToTensor(),\n","                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","                ]\n","            )\n","            img_data_tensor = transform(img_data)        \n","        img_ground_truth_tensor = torch.tensor(img_ground_truth, dtype=torch.long)\n","        return img_data_tensor, img_ground_truth_tensor\n","\n","\n","# Dataset + Dataloader\n","train_dataset = BirdDataset(train_img_paths, train_labels, transform=transform)\n","test_dataset = BirdDataset(test_img_paths, test_labels, transform=transform)\n","\n","train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n","\n","# Model\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","model = models.resnet101(pretrained=True)\n","\n","for param in model.parameters():\n","    param.requires_grad = True\n","\n","num_ftrs = model.fc.in_features\n","model.fc = nn.Linear(num_ftrs, len(label2name))\n","model = model.to(device)\n","\n","# Loss & optimizer\n","loss_func = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.fc.parameters(), lr=0.001)\n","epochs = 25\n","best_accuracy = 0.0\n","\n","# Training loop\n","for epoch in range(epochs):\n","    print(f'Epoch {epoch + 1}/{epochs}')\n","    model.train()\n","    running_loss = 0.0\n","    correct, total = 0, 0\n","\n","    for batch_data in train_dataloader:\n","        img_data, label_data = batch_data\n","        img_data, label_data = img_data.to(device), label_data.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(img_data)\n","        loss = loss_func(outputs, label_data)\n","\n","        predictions = outputs.argmax(dim=1)\n","        accuracy = sum(predictions == label_data) / len(label_data)\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","        correct += (predictions == label_data).sum().item()\n","        total += label_data.size(0)\n","\n","    epoch_loss = running_loss / len(train_dataloader)\n","    epoch_accuracy = correct / total\n","    print(f\"Train Loss: {epoch_loss:.6f}, Accuracy: {epoch_accuracy:.6f}\")\n","\n","    # Validation\n","    model.eval()\n","    val_loss = 0.0\n","    val_correct, val_total = 0, 0\n","\n","    with torch.no_grad():\n","        for batch_data in test_dataloader:\n","            img_data, label_data = batch_data\n","            img_data, label_data = img_data.to(device), label_data.to(device)\n","            outputs = model(img_data)\n","            loss = loss_func(outputs, label_data)\n","\n","            predictions = outputs.argmax(dim=1)\n","            val_correct += (predictions == label_data).sum().item()\n","            val_total += label_data.size(0)\n","            val_loss += loss.item()\n","\n","    test_loss = val_loss / len(test_dataloader)\n","    test_accuracy = val_correct / val_total\n","    print(f\"Test Loss: {test_loss:.6f}, Test Accuracy: {test_accuracy:.6f}\")\n","\n","    if test_accuracy > best_accuracy:\n","        best_accuracy = test_accuracy\n","        torch.save(model.state_dict(), f'best_model{epoch}.pth')\n","        print(f\"Saved best model! Accuracy: {best_accuracy:.6f}\")\n","\n","print(f'Best accuracy achieved = {best_accuracy}')\n"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":841289,"sourceId":1435929,"sourceType":"datasetVersion"}],"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"papermill":{"default_parameters":{},"duration":8082.179237,"end_time":"2025-05-02T06:57:51.500297","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-05-02T04:43:09.32106","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}