{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55c74c78",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-25T13:57:41.241734Z",
     "iopub.status.busy": "2025-04-25T13:57:41.241487Z",
     "iopub.status.idle": "2025-04-25T14:52:24.305354Z",
     "shell.execute_reply": "2025-04-25T14:52:24.304426Z"
    },
    "papermill": {
     "duration": 3283.068395,
     "end_time": "2025-04-25T14:52:24.306780",
     "exception": false,
     "start_time": "2025-04-25T13:57:41.238385",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth\n",
      "100%|██████████| 171M/171M [00:00<00:00, 235MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "Train Loss: 3.728604, Accuracy: 0.236987\n",
      "Test Loss: 2.529440, Test Accuracy: 0.401432\n",
      "Saved best model! Accuracy: 0.401432\n",
      "Epoch 2/20\n",
      "Train Loss: 1.882452, Accuracy: 0.574251\n",
      "Test Loss: 1.869770, Test Accuracy: 0.544229\n",
      "Saved best model! Accuracy: 0.544229\n",
      "Epoch 3/20\n",
      "Train Loss: 1.351135, Accuracy: 0.671022\n",
      "Test Loss: 1.692858, Test Accuracy: 0.560657\n",
      "Saved best model! Accuracy: 0.560657\n",
      "Epoch 4/20\n",
      "Train Loss: 1.076318, Accuracy: 0.746229\n",
      "Test Loss: 1.540023, Test Accuracy: 0.596883\n",
      "Saved best model! Accuracy: 0.596883\n",
      "Epoch 5/20\n",
      "Train Loss: 0.914268, Accuracy: 0.781071\n",
      "Test Loss: 1.543483, Test Accuracy: 0.591407\n",
      "Epoch 6/20\n",
      "Train Loss: 0.782334, Accuracy: 0.813257\n",
      "Test Loss: 1.481182, Test Accuracy: 0.592671\n",
      "Epoch 7/20\n",
      "Train Loss: 0.669025, Accuracy: 0.838857\n",
      "Test Loss: 1.497401, Test Accuracy: 0.597725\n",
      "Saved best model! Accuracy: 0.597725\n",
      "Epoch 8/20\n",
      "Train Loss: 0.593383, Accuracy: 0.860314\n",
      "Test Loss: 1.518669, Test Accuracy: 0.598989\n",
      "Saved best model! Accuracy: 0.598989\n",
      "Epoch 9/20\n",
      "Train Loss: 0.528083, Accuracy: 0.881453\n",
      "Test Loss: 1.462897, Test Accuracy: 0.589301\n",
      "Epoch 10/20\n",
      "Train Loss: 0.481752, Accuracy: 0.887933\n",
      "Test Loss: 1.446262, Test Accuracy: 0.609520\n",
      "Saved best model! Accuracy: 0.609520\n",
      "Epoch 11/20\n",
      "Train Loss: 0.419337, Accuracy: 0.907903\n",
      "Test Loss: 1.423019, Test Accuracy: 0.617102\n",
      "Saved best model! Accuracy: 0.617102\n",
      "Epoch 12/20\n",
      "Train Loss: 0.383726, Accuracy: 0.918101\n",
      "Test Loss: 1.464655, Test Accuracy: 0.601516\n",
      "Epoch 13/20\n",
      "Train Loss: 0.338595, Accuracy: 0.931910\n",
      "Test Loss: 1.468829, Test Accuracy: 0.599410\n",
      "Epoch 14/20\n",
      "Train Loss: 0.309442, Accuracy: 0.937115\n",
      "Test Loss: 1.424004, Test Accuracy: 0.610783\n",
      "Epoch 15/20\n",
      "Train Loss: 0.295026, Accuracy: 0.941470\n",
      "Test Loss: 1.503127, Test Accuracy: 0.602780\n",
      "Epoch 16/20\n",
      "Train Loss: 0.283216, Accuracy: 0.940302\n",
      "Test Loss: 1.519501, Test Accuracy: 0.601938\n",
      "Epoch 17/20\n",
      "Train Loss: 0.248646, Accuracy: 0.952836\n",
      "Test Loss: 1.533726, Test Accuracy: 0.620051\n",
      "Saved best model! Accuracy: 0.620051\n",
      "Epoch 18/20\n",
      "Train Loss: 0.238209, Accuracy: 0.954854\n",
      "Test Loss: 1.574306, Test Accuracy: 0.598568\n",
      "Epoch 19/20\n",
      "Train Loss: 0.222128, Accuracy: 0.958041\n",
      "Test Loss: 1.617172, Test Accuracy: 0.607835\n",
      "Epoch 20/20\n",
      "Train Loss: 0.191854, Accuracy: 0.971744\n",
      "Test Loss: 1.590249, Test Accuracy: 0.605307\n",
      "Best accuracy achieved = 0.620050547598989\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# Paths\n",
    "root = '/kaggle/input/bird-species-classification-220-categories'\n",
    "train_path = root + '/Train'\n",
    "test_path = root + '/Test'\n",
    "\n",
    "# Get labels\n",
    "train_labels = [i for i in os.listdir(train_path)]\n",
    "test_labels = [i for i in os.listdir(test_path)]\n",
    "\n",
    "tmp_train_img_paths = [train_path + '/' + j for j in train_labels]\n",
    "tmp_test_img_paths = [test_path + '/' + j for j in test_labels]\n",
    "train_img_paths, test_img_paths = [], []\n",
    "\n",
    "for i in tmp_train_img_paths:\n",
    "    for j in os.listdir(i):\n",
    "        train_img_paths.append(i + '/' + j)\n",
    "for i in tmp_test_img_paths:\n",
    "    for j in os.listdir(i):\n",
    "        test_img_paths.append(i + '/' + j)\n",
    "del tmp_test_img_paths, tmp_train_img_paths\n",
    "\n",
    "random.shuffle(train_img_paths)\n",
    "random.shuffle(test_img_paths)\n",
    "\n",
    "# label2name, name2label\n",
    "label2name, name2label = {}, {}\n",
    "for i in range(len(train_labels)):\n",
    "    label2name[i] = train_labels[i]\n",
    "    name2label[train_labels[i]] = i\n",
    "\n",
    "# ground truth\n",
    "train_labels, test_labels = [], []\n",
    "for i in train_img_paths:\n",
    "    train_labels.append(name2label[i.split('/')[-2]])\n",
    "for j in test_img_paths:\n",
    "    test_labels.append(name2label[j.split('/')[-2]])\n",
    "\n",
    "# Transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Dataset\n",
    "class BirdDataset(Dataset):\n",
    "    def __init__(self, data, labels, transform=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, item_index):\n",
    "        img_path = self.data[item_index]\n",
    "        img_ground_truth = self.labels[item_index]\n",
    "        img_data = cv2.imread(img_path)\n",
    "        img_data = cv2.cvtColor(img_data, cv2.COLOR_BGR2RGB)\n",
    "        if self.transform:\n",
    "            img_data = self.transform(img_data)\n",
    "        img_ground_truth_tensor = torch.tensor(img_ground_truth, dtype=torch.long)\n",
    "        return img_data, img_ground_truth_tensor\n",
    "\n",
    "# Dataset + Dataloader\n",
    "train_dataset = BirdDataset(train_img_paths, train_labels, transform=transform)\n",
    "test_dataset = BirdDataset(test_img_paths, test_labels, transform=transform)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Model\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = models.resnet101(pretrained=True)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, len(label2name))\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss & optimizer\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "epochs = 20\n",
    "best_accuracy = 0.0\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    print(f'Epoch {epoch + 1}/{epochs}')\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    for batch_data in train_dataloader:\n",
    "        img_data, label_data = batch_data\n",
    "        img_data, label_data = img_data.to(device), label_data.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(img_data)\n",
    "        loss = loss_func(outputs, label_data)\n",
    "\n",
    "        predictions = outputs.argmax(dim=1)\n",
    "        accuracy = sum(predictions == label_data) / len(label_data)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        correct += (predictions == label_data).sum().item()\n",
    "        total += label_data.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataloader)\n",
    "    epoch_accuracy = correct / total\n",
    "    print(f\"Train Loss: {epoch_loss:.6f}, Accuracy: {epoch_accuracy:.6f}\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct, val_total = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_data in test_dataloader:\n",
    "            img_data, label_data = batch_data\n",
    "            img_data, label_data = img_data.to(device), label_data.to(device)\n",
    "            outputs = model(img_data)\n",
    "            loss = loss_func(outputs, label_data)\n",
    "\n",
    "            predictions = outputs.argmax(dim=1)\n",
    "            val_correct += (predictions == label_data).sum().item()\n",
    "            val_total += label_data.size(0)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    test_loss = val_loss / len(test_dataloader)\n",
    "    test_accuracy = val_correct / val_total\n",
    "    print(f\"Test Loss: {test_loss:.6f}, Test Accuracy: {test_accuracy:.6f}\")\n",
    "\n",
    "    if test_accuracy > best_accuracy:\n",
    "        best_accuracy = test_accuracy\n",
    "        torch.save(model.state_dict(), f'best_model{epoch}.pth')\n",
    "        print(f\"Saved best model! Accuracy: {best_accuracy:.6f}\")\n",
    "\n",
    "print(f'Best accuracy achieved = {best_accuracy}')\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 841289,
     "sourceId": 1435929,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3289.857423,
   "end_time": "2025-04-25T14:52:27.113607",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-25T13:57:37.256184",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
